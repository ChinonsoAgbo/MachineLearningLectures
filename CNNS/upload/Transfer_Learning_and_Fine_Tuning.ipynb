{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5439fa2b-db84-4534-8e75-3d6558bb1d0a",
   "metadata": {},
   "source": [
    "# Transfer Learning and Fine Tuning\n",
    "See https://keras.io/guides/transfer_learning/"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef35e7e0-e242-40c8-81c2-d1f4b91d95cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:02:44.168805Z",
     "start_time": "2024-06-19T10:02:44.165951Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "c7e3b129-6579-4eeb-a8a7-40e084e1561e",
   "metadata": {},
   "source": [
    "## The Cats vs Dogs Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64144318-c798-4f4e-b288-b9d1abfae675",
   "metadata": {},
   "source": [
    "In this example a CNN classifier pre trained on ImageNet data will be transfer learned to a binary classifier and fine tuned, distinguishing between cats and dogs. As can be seen below. a few hundred images already suffice to reach high accuracies using this technique"
   ]
  },
  {
   "cell_type": "code",
   "id": "2f4b7a67-c12b-4ae9-90ba-795da392f97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:01:37.726859Z",
     "start_time": "2024-06-19T10:01:37.565506Z"
    }
   },
   "source": [
    "tfds.disable_progress_bar()\n",
    "\n",
    "train_ds, validation_ds, test_ds = tfds.load(\n",
    "    \"cats_vs_dogs\",\n",
    "    split=[\"train[:2%]\", \"train[40%:42%]\", \"train[50%:52%]\"],\n",
    "    as_supervised=True,  # Include labels\n",
    ")\n",
    "\n",
    "print(\"Number of training samples: %d\" % tf.data.experimental.cardinality(train_ds))\n",
    "print(\n",
    "    \"Number of validation samples: %d\" % tf.data.experimental.cardinality(validation_ds)\n",
    ")\n",
    "print(\"Number of test samples: %d\" % tf.data.experimental.cardinality(test_ds))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Chinonso Agbo\\tensorflow_datasets\\cats_vs_dogs\\4.0.1...\u001B[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"There is no item named 'PetImages\\\\\\\\Cat\\\\\\\\0.jpg' in the archive\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m tfds\u001B[38;5;241m.\u001B[39mdisable_progress_bar()\n\u001B[1;32m----> 3\u001B[0m train_ds, validation_ds, test_ds \u001B[38;5;241m=\u001B[39m \u001B[43mtfds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcats_vs_dogs\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain[:2\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain[40\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m:42\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain[50\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m:52\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43m]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mas_supervised\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Include labels\u001B[39;49;00m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of training samples: \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mcardinality(train_ds))\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of validation samples: \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mcardinality(validation_ds)\n\u001B[0;32m     12\u001B[0m )\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001B[0m, in \u001B[0;36m_FunctionDecorator.__call__\u001B[1;34m(self, function, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    167\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_call()\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    171\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:647\u001B[0m, in \u001B[0;36mload\u001B[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001B[0m\n\u001B[0;32m    528\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Loads the named dataset into a `tf.data.Dataset`.\u001B[39;00m\n\u001B[0;32m    529\u001B[0m \n\u001B[0;32m    530\u001B[0m \u001B[38;5;124;03m`tfds.load` is a convenience method that:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    639\u001B[0m \u001B[38;5;124;03m    Split-specific information is available in `ds_info.splits`.\u001B[39;00m\n\u001B[0;32m    640\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m  \u001B[38;5;66;03m# fmt: skip\u001B[39;00m\n\u001B[0;32m    641\u001B[0m dbuilder \u001B[38;5;241m=\u001B[39m _fetch_builder(\n\u001B[0;32m    642\u001B[0m     name,\n\u001B[0;32m    643\u001B[0m     data_dir,\n\u001B[0;32m    644\u001B[0m     builder_kwargs,\n\u001B[0;32m    645\u001B[0m     try_gcs,\n\u001B[0;32m    646\u001B[0m )\n\u001B[1;32m--> 647\u001B[0m \u001B[43m_download_and_prepare_builder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdbuilder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m as_dataset_kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    650\u001B[0m   as_dataset_kwargs \u001B[38;5;241m=\u001B[39m {}\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:506\u001B[0m, in \u001B[0;36m_download_and_prepare_builder\u001B[1;34m(dbuilder, download, download_and_prepare_kwargs)\u001B[0m\n\u001B[0;32m    504\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download:\n\u001B[0;32m    505\u001B[0m   download_and_prepare_kwargs \u001B[38;5;241m=\u001B[39m download_and_prepare_kwargs \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m--> 506\u001B[0m   \u001B[43mdbuilder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001B[0m, in \u001B[0;36m_FunctionDecorator.__call__\u001B[1;34m(self, function, instance, args, kwargs)\u001B[0m\n\u001B[0;32m    167\u001B[0m metadata \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_start_call()\n\u001B[0;32m    168\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 169\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    170\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m    171\u001B[0m   metadata\u001B[38;5;241m.\u001B[39mmark_error()\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:699\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[1;34m(self, download_dir, download_config, file_format)\u001B[0m\n\u001B[0;32m    697\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mread_from_directory(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_dir)\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 699\u001B[0m   \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    700\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    701\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    704\u001B[0m   \u001B[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001B[39;00m\n\u001B[0;32m    705\u001B[0m   \u001B[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001B[39;00m\n\u001B[0;32m    706\u001B[0m   \u001B[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001B[39;00m\n\u001B[0;32m    707\u001B[0m   \u001B[38;5;66;03m# when reading from package data.\u001B[39;00m\n\u001B[0;32m    708\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdownload_size \u001B[38;5;241m=\u001B[39m dl_manager\u001B[38;5;241m.\u001B[39mdownloaded_size\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1669\u001B[0m, in \u001B[0;36mGeneratorBasedBuilder._download_and_prepare\u001B[1;34m(self, dl_manager, download_config)\u001B[0m\n\u001B[0;32m   1666\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m download_config\u001B[38;5;241m.\u001B[39mmax_examples_per_split \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m   1667\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m-> 1669\u001B[0m split_infos \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_generate_splits\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1671\u001B[0m \u001B[38;5;66;03m# Update the info object with the splits.\u001B[39;00m\n\u001B[0;32m   1672\u001B[0m split_dict \u001B[38;5;241m=\u001B[39m splits_lib\u001B[38;5;241m.\u001B[39mSplitDict(split_infos)\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1644\u001B[0m, in \u001B[0;36mGeneratorBasedBuilder._generate_splits\u001B[1;34m(self, dl_manager, download_config)\u001B[0m\n\u001B[0;32m   1637\u001B[0m   \u001B[38;5;28;01mfor\u001B[39;00m split_name, generator \u001B[38;5;129;01min\u001B[39;00m utils\u001B[38;5;241m.\u001B[39mtqdm(\n\u001B[0;32m   1638\u001B[0m       split_generators\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[0;32m   1639\u001B[0m       desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating splits...\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1640\u001B[0m       unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m splits\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1641\u001B[0m       leave\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   1642\u001B[0m   ):\n\u001B[0;32m   1643\u001B[0m     filename_template \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_filename_template(split_name\u001B[38;5;241m=\u001B[39msplit_name)\n\u001B[1;32m-> 1644\u001B[0m     future \u001B[38;5;241m=\u001B[39m \u001B[43msplit_builder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit_split_generation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1645\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msplit_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1646\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename_template\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilename_template\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1648\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable_shuffling\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdisable_shuffling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1649\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1650\u001B[0m     split_info_futures\u001B[38;5;241m.\u001B[39mappend(future)\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;66;03m# Process the result of the beam pipeline.\u001B[39;00m\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:331\u001B[0m, in \u001B[0;36mSplitBuilder.submit_split_generation\u001B[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001B[0m\n\u001B[0;32m    328\u001B[0m \u001B[38;5;66;03m# Depending on the type of generator, we use the corresponding\u001B[39;00m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;66;03m# `_build_from_xyz` method.\u001B[39;00m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(generator, Iterable):\n\u001B[1;32m--> 331\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_from_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbuild_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    332\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# Otherwise, beam required\u001B[39;00m\n\u001B[0;32m    333\u001B[0m   unknown_generator_type \u001B[38;5;241m=\u001B[39m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    334\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInvalid split generator value for split `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msplit_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`. \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    335\u001B[0m       \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mExpected generator or apache_beam object. Got: \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    336\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(generator)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    337\u001B[0m   )\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\core\\split_builder.py:391\u001B[0m, in \u001B[0;36mSplitBuilder._build_from_generator\u001B[1;34m(self, split_name, generator, filename_template, disable_shuffling)\u001B[0m\n\u001B[0;32m    381\u001B[0m serialized_info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_features\u001B[38;5;241m.\u001B[39mget_serialized_info()\n\u001B[0;32m    382\u001B[0m writer \u001B[38;5;241m=\u001B[39m writer_lib\u001B[38;5;241m.\u001B[39mWriter(\n\u001B[0;32m    383\u001B[0m     serializer\u001B[38;5;241m=\u001B[39mexample_serializer\u001B[38;5;241m.\u001B[39mExampleSerializer(serialized_info),\n\u001B[0;32m    384\u001B[0m     filename_template\u001B[38;5;241m=\u001B[39mfilename_template,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    389\u001B[0m     ignore_duplicates\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ignore_duplicates,\n\u001B[0;32m    390\u001B[0m )\n\u001B[1;32m--> 391\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGenerating \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43msplit_name\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m examples...\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[43munit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m examples\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtotal_num_examples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43mleave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmininterval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    398\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m    399\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mtry\u001B[39;49;00m\u001B[43m:\u001B[49m\n\u001B[0;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexample\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_features\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_example\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\studium\\Semester4\\KI-Programmiergrundlagen\\codeBeispiele\\.venv\\Lib\\site-packages\\tensorflow_datasets\\image_classification\\cats_vs_dogs.py:117\u001B[0m, in \u001B[0;36mCatsVsDogs._generate_examples\u001B[1;34m(self, archive)\u001B[0m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m zipfile\u001B[38;5;241m.\u001B[39mZipFile(buffer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m new_zip:\n\u001B[0;32m    116\u001B[0m   new_zip\u001B[38;5;241m.\u001B[39mwritestr(fname, img_recoded\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m--> 117\u001B[0m new_fobj \u001B[38;5;241m=\u001B[39m \u001B[43mzipfile\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mZipFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    119\u001B[0m record \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m: new_fobj,\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage/filename\u001B[39m\u001B[38;5;124m\"\u001B[39m: fname,\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m\"\u001B[39m: label,\n\u001B[0;32m    123\u001B[0m }\n\u001B[0;32m    124\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m fname, record\n",
      "File \u001B[1;32mD:\\Applications\\Python\\Python312\\Lib\\zipfile\\__init__.py:1595\u001B[0m, in \u001B[0;36mZipFile.open\u001B[1;34m(self, name, mode, pwd, force_zip64)\u001B[0m\n\u001B[0;32m   1592\u001B[0m     zinfo\u001B[38;5;241m.\u001B[39m_compresslevel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompresslevel\n\u001B[0;32m   1593\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1594\u001B[0m     \u001B[38;5;66;03m# Get info object for name\u001B[39;00m\n\u001B[1;32m-> 1595\u001B[0m     zinfo \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1597\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m   1598\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_open_to_write(zinfo, force_zip64\u001B[38;5;241m=\u001B[39mforce_zip64)\n",
      "File \u001B[1;32mD:\\Applications\\Python\\Python312\\Lib\\zipfile\\__init__.py:1524\u001B[0m, in \u001B[0;36mZipFile.getinfo\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1522\u001B[0m info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mNameToInfo\u001B[38;5;241m.\u001B[39mget(name)\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m info \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1524\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThere is no item named \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m in the archive\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m name)\n\u001B[0;32m   1527\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m info\n",
      "\u001B[1;31mKeyError\u001B[0m: \"There is no item named 'PetImages\\\\\\\\Cat\\\\\\\\0.jpg' in the archive\""
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "7e0f9fc2-feaf-4c8b-8385-7bd16ec6653d",
   "metadata": {},
   "source": [
    "#### Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "id": "ddef4ab1-3990-43a0-ae1d-bda32812af14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T10:01:37.727869Z",
     "start_time": "2024-06-19T10:01:37.727869Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, (image, label) in enumerate(train_ds.take(9)):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(int(label))\n",
    "    plt.axis(\"off\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f8028756-fff3-4c22-ae5e-f3e06381cd01",
   "metadata": {},
   "source": [
    "#### Setting up the preprocessing pipe line"
   ]
  },
  {
   "cell_type": "code",
   "id": "7bee9d97-a97d-4e43-8b51-8073e8556763",
   "metadata": {},
   "source": [
    "size = (224, 224)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "validation_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y))\n",
    "test_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad0b0b65-30e0-4192-9b57-956d35075d84",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "validation_ds = validation_ds.cache().batch(batch_size).prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a00a3b8a-f404-48fb-930b-3f57d2fc5333",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef963ad8-2412-4f96-938f-315088c7b5c4",
   "metadata": {},
   "source": [
    "Another popular method to avoid overfitting on little data is data augmentation. Images are randomly transformed, using selected operations, such that no images passes the training twice exaclty the same."
   ]
  },
  {
   "cell_type": "code",
   "id": "8a5dd670-3bc7-413f-bed8-e862ae56bc96",
   "metadata": {},
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "for images, labels in train_ds.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image = images[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(\n",
    "            tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        plt.imshow(augmented_image[0].numpy().astype(\"int32\"))\n",
    "        plt.title(int(labels[0]))\n",
    "        plt.axis(\"off\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6da8e6b2-4d89-4a47-a677-c994504abf4b",
   "metadata": {},
   "source": [
    "## Pretrained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410586e1-9aae-4302-aad7-0ad8c0268556",
   "metadata": {},
   "source": [
    "Many well published pretrained models can be found for keras on https://keras.io/api/applications/."
   ]
  },
  {
   "cell_type": "code",
   "id": "165b5f43-fc82-4a23-a96e-51afd932962d",
   "metadata": {},
   "source": [
    "base_model = keras.applications.MobileNet(\n",
    "    # Load weights pre-trained on ImageNet.\n",
    "    weights=\"imagenet\",  \n",
    "    input_shape=(224, 224, 3),\n",
    "    # Do not include the ImageNet classifier at the top.\n",
    "    include_top=False,\n",
    ") \n",
    "# Freeze the base_model\n",
    "base_model.trainable = False\n",
    "# As can be seen in the summary below, none of the models weights will be adapted during training.\n",
    "base_model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c690fbc0-032b-4337-b9a7-5208b2e21968",
   "metadata": {},
   "source": [
    "We add the preprocessing and the scaling to the model and add a new Dense Layer on top of the pretrained model to adjust the feature extractor to the new taks during the transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "id": "1120b2d9-c806-433c-90fe-98ad98764e71",
   "metadata": {},
   "source": [
    "# Create new model on top\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)  # Apply random data augmentation\n",
    "\n",
    "# Pre-trained Xception weights requires that input be scaled\n",
    "# from (0, 255) to a range of (-1., +1.), the rescaling layer\n",
    "# outputs: `(inputs * scale) + offset`\n",
    "scale_layer = keras.layers.Rescaling(scale=1 / 127.5, offset=-1)\n",
    "x = scale_layer(x)\n",
    "\n",
    "# The base model contains batchnorm layers. We want to keep them in inference mode\n",
    "# when we unfreeze the base model for fine-tuning, so we make sure that the\n",
    "# base_model is running in inference mode here.\n",
    "x = base_model(x, training=False)\n",
    "# TODO: Add a GlobalAveragePooling, a Dropout and a Dense layer to the base model\n",
    "outputs = x\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ae3dd73a-76e6-47bc-9a0e-cbc3326cad1b",
   "metadata": {},
   "source": [
    "Training only the few parameters in the newly added top layer"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2126110-25f4-4795-b63b-5c30b747dfdd",
   "metadata": {},
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.01),\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n",
    "epochs = 10\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "68b9d790-21cf-45ae-98e6-5c1cc60a0782",
   "metadata": {},
   "source": [
    "# Unfreeze the base_model. Note that it keeps running in inference mode\n",
    "# since we passed `training=False` when calling it. This means that\n",
    "# the batchnorm layers will not update their batch statistics.\n",
    "# This prevents the batchnorm layers from undoing all the training\n",
    "# we've done so far.\n",
    "base_model.trainable = True\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a9a45c7a-d8e4-4941-b43e-a72266480914",
   "metadata": {},
   "source": [
    "epochs = 12\n",
    "model.fit(train_ds, epochs=epochs, validation_data=validation_ds)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "928efdcb-eb6a-4568-a3f9-ed3bf061e682",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
