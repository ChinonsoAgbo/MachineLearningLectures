{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4969af8d-a75f-4c00-8e24-9a236c312883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from ipynb.fs.defs._2_Building_a_ViT import MyVit\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4226a51-8c44-4528-8a27-0ce65a8ae884",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "# INFO: The PyTorch uses a different tensor shape than Tensorflpow\n",
    "# Tensorflow: [batch_size, height, width, channels]\n",
    "# Pytorch: [batch_size, channels, height, width]\n",
    "train_loader = DataLoader(training_data, batch_size=64)\n",
    "test_loader = DataLoader(test_data, batch_size=128)\n",
    "x_sample, y_sample = next(iter(train_loader))\n",
    "image_shape = x_sample.shape\n",
    "print (f\"Image shape is: {image_shape} (batch size, channels, height, width)\")\n",
    "plt.matshow(x_sample[0][0], cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86436904-175e-4075-ad1c-2407d3f6beba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device: \", device)\n",
    "model = MyVit(x_sample.shape,\n",
    "              classes=10,\n",
    "              p_size=7,\n",
    "              embedded_dimension=8,\n",
    "              n_heads=4,\n",
    "              n_blocks=2)\n",
    "model.to(device)\n",
    "n_epochs = 10\n",
    "learning_rate = 0.005\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f81dcb-d64b-4379-a94d-ba5ff168b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(n_epochs, desc=\"Training\"):\n",
    "    train_loss = 0.0\n",
    "    batch_counter = 0\n",
    "    pbar = tqdm(train_loader,\n",
    "                desc=f\"Epoch {epoch + 1}\",\n",
    "                leave=False,\n",
    "                position=0)\n",
    "    for batch in pbar:\n",
    "        batch_counter += 1\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "\n",
    "        train_loss += loss.detach().cpu().item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f\"training loss: {train_loss / batch_counter:.2f}\")\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs} loss: {(train_loss / len(train_loader)):.2f}\")\n",
    "    \n",
    "    # Test loop\n",
    "    batch_counter = 0\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0, 0\n",
    "        test_loss = 0.0\n",
    "        for batch in tqdm(test_loader, desc=\"Testing\", leave=False, position=0):\n",
    "            batch_counter += 1\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            test_loss += loss.detach().cpu().item() / len(test_loader)\n",
    "\n",
    "            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
    "            total += len(x)\n",
    "\n",
    "        print(f\"Test loss: {test_loss:.2f}\")\n",
    "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
    "\n",
    "\n",
    "torch.save(model, \"MNIST_transformer.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0833cf4e-072e-49f5-b4fc-78f0b894e9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd9321-f287-45fb-bb7b-14da29dff24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
